{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute & Compare Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 29.2 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from gensim.models import KeyedVectors\n",
    "from fse import SIF\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from re import sub\n",
    "\n",
    "import pandas as pd\n",
    "from wordfreq import get_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/TF2alpha/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained word2vec model\n",
    "model = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "\n",
    "freq_dict = get_frequency_dict(\"en\", wordlist='best')\n",
    "\n",
    "for w in model.vocab:\n",
    "    if w in freq_dict:\n",
    "        model.vocab[w].count = int(freq_dict[w] * 2**24)\n",
    "    else:\n",
    "        model.vocab[w].count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 82.5 ms\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/reddit/\"\n",
    "\n",
    "p = pathlib.Path(data_path)\n",
    "\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(\"Directory does not exist.\")\n",
    "\n",
    "file_list=[]\n",
    "for f in p.iterdir():\n",
    "    if f.is_file():\n",
    "        file_list.append(f)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "        \n",
    "for i, f in enumerate(file_list):\n",
    "    df_tmp = pd.read_csv(f)\n",
    "    df_tmp[\"label\"] = i\n",
    "    df_tmp = df_tmp[[\"title\", \"label\"]]\n",
    "    data = pd.concat([data, df_tmp])\n",
    "    \n",
    "min_data = np.min(np.unique(data.label.values, return_counts=True)[1])\n",
    "labels = np.unique(data.label.values)\n",
    "\n",
    "data_balanced = pd.DataFrame()\n",
    "\n",
    "for i in labels:\n",
    "    data_balanced = pd.concat([data_balanced, data[data[\"label\"] == i].sample(n=min_data, random_state=42)])\n",
    "    \n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "y = np.array(data_balanced.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 135 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/TF2alpha/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def normalize_text(sentence):\n",
    "    return [sub(\"[^a-zA-Z]\", \"\", w.lower()) for w in sentence.split()] \n",
    "\n",
    "data_balanced[\"title_processed\"] = (data_balanced['title'].apply(normalize_text))\n",
    "\n",
    "corpus = data_balanced[\"title_processed\"].values.tolist()\n",
    "labels = data_balanced.label.values.tolist()\n",
    "\n",
    "corpus = [[w for w in s if w in model.wv.vocab] for s in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.3 ms\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_bow = count_vect.fit_transform([\" \".join(s) for s in corpus])\n",
    "x_tfidf = TfidfTransformer(use_idf=True).fit_transform(x_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "cbow_model = SIF(model, alpha=0, components=0)\n",
    "x_cbow = cbow_model.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "sif_model = SIF(model, alpha=1e-3, components=1)\n",
    "x_sif = sif_model.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "\n",
    "mds = dict()\n",
    "\n",
    "mds[\"BOW\"] = x_bow\n",
    "mds[\"TFIDF\"] = x_tfidf\n",
    "mds[\"CBOW\"] = x_cbow\n",
    "mds[\"SIF\"] = x_sif\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "with pd.ExcelWriter(\"../excel/pcomp_\"+date_time+\".xlsx\") as writer:\n",
    "    \n",
    "    for k in mds.keys():\n",
    "        x_train, x_test, y_train, y_test = train_test_split(mds[k], labels, test_size=0.5, random_state=42)\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        df = pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)).T\n",
    "        df.to_excel(writer, sheet_name=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STS Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the STS Benchmark Dataset from: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1041: expected 7 fields, saw 8\\nSkipping line 1065: expected 7 fields, saw 8\\nSkipping line 1082: expected 7 fields, saw 8\\nSkipping line 1136: expected 7 fields, saw 8\\nSkipping line 1149: expected 7 fields, saw 8\\nSkipping line 1449: expected 7 fields, saw 9\\nSkipping line 1450: expected 7 fields, saw 9\\nSkipping line 1451: expected 7 fields, saw 9\\nSkipping line 1452: expected 7 fields, saw 9\\nSkipping line 1453: expected 7 fields, saw 9\\nSkipping line 1454: expected 7 fields, saw 9\\nSkipping line 1455: expected 7 fields, saw 9\\nSkipping line 1456: expected 7 fields, saw 9\\nSkipping line 1457: expected 7 fields, saw 9\\nSkipping line 1458: expected 7 fields, saw 9\\nSkipping line 1459: expected 7 fields, saw 9\\nSkipping line 1460: expected 7 fields, saw 9\\nSkipping line 1461: expected 7 fields, saw 9\\nSkipping line 1462: expected 7 fields, saw 9\\nSkipping line 1463: expected 7 fields, saw 9\\nSkipping line 1464: expected 7 fields, saw 9\\nSkipping line 1465: expected 7 fields, saw 9\\nSkipping line 1466: expected 7 fields, saw 9\\nSkipping line 1467: expected 7 fields, saw 9\\nSkipping line 1468: expected 7 fields, saw 9\\nSkipping line 1469: expected 7 fields, saw 9\\nSkipping line 1470: expected 7 fields, saw 9\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 443 ms\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/stsbenchmark/sts-dev.csv\"\n",
    "\n",
    "p = pathlib.Path(file_path)\n",
    "\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(\"Directory does not exist.\")\n",
    "\n",
    "sts_data = pd.read_csv(file_path, sep=\"\\t\", error_bad_lines=False, header=None)\n",
    "sts_data = sts_data[[5,6,4]]\n",
    "sts_data.columns = [\"A\", \"B\", \"sim\"]\n",
    "sts_data.dropna(inplace=True)\n",
    "sts_data.A = (sts_data.A.apply(normalize_text))\n",
    "sts_data.B = (sts_data.B.apply(normalize_text))\n",
    "\n",
    "sents_a = sts_data.A.values.tolist()\n",
    "sents_b = sts_data.B.values.tolist()\n",
    "assert len(sents_a) == len(sents_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 246 ms\n"
     ]
    }
   ],
   "source": [
    "from gensim.matutils import unitvec\n",
    "\n",
    "cbow_vecs_a = cbow_model.train(sents_a)\n",
    "cbow_vecs_b = cbow_model.train(sents_b)\n",
    "\n",
    "sif_vecs_a = sif_model.train(sents_a)\n",
    "sif_vecs_b = sif_model.train(sents_b)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results[\"STS\"] = sts_data.sim\n",
    "\n",
    "def pearson_correlation(mat_a, mat_b):\n",
    "    assert mat_a.shape == mat_b.shape\n",
    "    results = []\n",
    "    for i in range(len(mat_a)):\n",
    "        results.append(unitvec(mat_a[i]).dot(unitvec(mat_b[i])))\n",
    "    return results\n",
    "\n",
    "results[\"CBOW\"] = pearson_correlation(cbow_vecs_a, cbow_vecs_b)\n",
    "results[\"SIF\"] = pearson_correlation(sif_vecs_a, sif_vecs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "results = results.corr()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "results.to_excel(\"../excel/STScomp_\"+date_time+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STS</th>\n",
       "      <th>CBOW</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722721</td>\n",
       "      <td>0.775733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW</th>\n",
       "      <td>0.722721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF</th>\n",
       "      <td>0.775733</td>\n",
       "      <td>0.920911</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           STS      CBOW       SIF\n",
       "STS   1.000000  0.722721  0.775733\n",
       "CBOW  0.722721  1.000000  0.920911\n",
       "SIF   0.775733  0.920911  1.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.9 ms\n"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
