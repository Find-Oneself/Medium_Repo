{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Sentence Embeddings Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from gensim.models import KeyedVectors\n",
    "from models.sif import SIF\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from re import sub\n",
    "\n",
    "import pandas as pd\n",
    "from wordfreq import get_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/TF2alpha/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained word2vec model\n",
    "model = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "\n",
    "freq_dict = get_frequency_dict(\"en\", wordlist='best')\n",
    "\n",
    "for w in model.vocab:\n",
    "    if w in freq_dict:\n",
    "        model.vocab[w].count = int(freq_dict[w] * 2**24)\n",
    "    else:\n",
    "        model.vocab[w].count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 75.9 ms\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/reddit/\"\n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "\n",
    "p = pathlib.Path(data_path)\n",
    "\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(\"Directory does not exist.\")\n",
    "\n",
    "file_list=[]\n",
    "for f in p.iterdir():\n",
    "    if f.is_file():\n",
    "        file_list.append(f)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "        \n",
    "for i, f in enumerate(file_list):\n",
    "    df_tmp = pd.read_csv(f)\n",
    "    df_tmp[\"label\"] = i\n",
    "    df_tmp = df_tmp[[\"title\", \"label\"]]\n",
    "    data = pd.concat([data, df_tmp])\n",
    "    \n",
    "min_data = np.min(np.unique(data.label.values, return_counts=True)[1])\n",
    "labels = np.unique(data.label.values)\n",
    "\n",
    "data_balanced = pd.DataFrame()\n",
    "\n",
    "for i in labels:\n",
    "    data_balanced = pd.concat([data_balanced, data[data[\"label\"] == i].sample(n=min_data, random_state=42)])\n",
    "    \n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "y = np.array(data_balanced.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 124 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/TF2alpha/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(sentence):\n",
    "    return [sub(\"[^a-zA-Z]\", \"\", w.lower()) for w in sentence.split()] \n",
    "data_balanced[\"title_processed\"] = (data_balanced['title'].apply(normalize_text))\n",
    "\n",
    "corpus = data_balanced[\"title_processed\"].values.tolist()\n",
    "labels = data_balanced.label.values.tolist()\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "#model = Word2Vec()\n",
    "#model.build_vocab(corpus)\n",
    "\n",
    "corpus = [[w for w in s if w in model.wv.vocab] for s in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_bow = count_vect.fit_transform([\" \".join(s) for s in corpus])\n",
    "x_tfidf = TfidfTransformer(use_idf=True).fit_transform(x_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_model = SIF(alpha=1e-3, components=1)\n",
    "x_sif = sif_model.train(model, corpus)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cbow_model = SIF(alpha=0, components=0)\n",
    "x_cbow = cbow_model.train(model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_data = [x_bow, x_tfidf, x_cbow]\n",
    "\n",
    "for d in x_data:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(d, labels, test_size=0.33, random_state=42)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
